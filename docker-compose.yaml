version: '3.8'

services:

  # Carla server container
  carla_server:
    build:
      context: ./docker/carla_server_node/
      dockerfile: Dockerfile
    container_name: carla_server
    runtime: nvidia
    ports:
      - 2000-2002:2000-2002
    command: /bin/bash -c "./CarlaUE4.sh -nosound -carla-server -RenderOffscreen -world-port=2000 -carla-streaming-port=0"

  # Carla ROS bridge container
  bridge:
    build:
      context: ./docker
      dockerfile: ./ros_carla_bridge/Dockerfile
    container_name: carla_ros_bridge
    command: ros2 launch carla_ros_bridge carla_ros_bridge_with_example_ego_vehicle.launch.py host:=carla_server timeout:=5
    runtime: nvidia
    restart: always
    depends_on: 
      carla_server:
        condition: service_started

  # Custom ROS2 container
  ros2_container:
    build:
      context: ./docker/ros2_container/
      dockerfile: Dockerfile
    container_name: ros2_container
    command: ros2 run ros2_utils list_topics_node
    depends_on: 
      bridge:
        condition: service_started

  # Custom Carla Node
  carla_client:
    build:
      context: ./docker
      dockerfile: ./carla_client_node/Dockerfile
    container_name: carla_client
    restart: always
    depends_on: 
      bridge:
        condition: service_started

  # foxglove to visualize live data 
  foxglove_bridge:
    build:
      context: ./docker/foxglove_bridge/
      dockerfile: Dockerfile
    ports:
      - 8765:8765
    container_name: foxglove_bridge
    command: ros2 launch foxglove_bridge foxglove_bridge_launch.xml port:=8765
    restart: always
    depends_on: 
      bridge:
        condition: service_started

  # Example ros talker node
  ros_talker:
    image: osrf/ros:humble-desktop-full
    container_name: ros_talker
    command: ros2 run demo_nodes_cpp talker

   # Example ros listener node
  ros_listener:
    image: osrf/ros:humble-desktop-full
    container_name: ros_listener
    command: ros2 run demo_nodes_cpp listener
    depends_on:
      - ros_talker
